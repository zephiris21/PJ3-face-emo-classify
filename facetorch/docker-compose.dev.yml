version: "3.8"
services:

  facetorch-dev:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.dev
    volumes:
      - ./:/opt/facetorch
    entrypoint: [ "/bin/bash" ]

  facetorch-dev-gpu:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.dev.gpu
    volumes:
      - ./:/opt/facetorch
    shm_size: 8gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    entrypoint: [ "/bin/bash" ]

  facetorch-tests:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.tests
    volumes:
      - ./:/opt/facetorch
    entrypoint:
      [
        "pytest",
        "-v",
        "--cov=facetorch",
        "--cov-report=term",
        "--cov-fail-under=95"
      ]

  facetorch-dev-example:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.dev
    volumes:
      - ./:/opt/facetorch
    entrypoint: [ "python", "scripts/example.py" ]

  facetorch-lock:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.lock
    volumes:
      - ./:/opt/facetorch
    entrypoint:
      [
        "conda-lock",
        "-p",
        "linux-64",
        "-f",
        "environment.yml",
        "--lockfile",
        "new.conda-lock.yml"
      ]

  facetorch-lock-gpu:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.lock
    volumes:
      - ./:/opt/facetorch
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    entrypoint:
      [
        "conda-lock",
        "-p",
        "linux-64",
        "-f",
        "gpu.environment.yml",
        "--lockfile",
        "new.gpu.conda-lock.yml"
      ]
